model:
  N: 6
  d_model: 512
  d_ff: 2048
  num_heads: 8
  dropout: 0.1
  attn_dropout: 0.0
  activation: "relu"
  share_embeddings: true
  tie_softmax_weight: true
  pos_encoding: "sinusoidal"
  label_smoothing: 0.1
  vocab_size: 37000

data:
  dataset: "wmt14"
  lang_pair: "en-de"
  max_src_len: 256
  max_tgt_len: 256
  min_len: 1
  tokenizer_dir: "work/tokenizer_en_de"
  vocab_size: 37000
  use_shared_vocab: true
  max_tokens_per_batch: 50000
  num_buckets: 8
  cache_dir: null

optim:
  lr: 5.0e-4
  betas: [0.9, 0.98]
  eps: 1.0e-9
  weight_decay: 0.0
  warmup_steps: 4000
  max_steps: 100000
  grad_clip: 1.0

runtime:
  seed: 42
  device: "cuda"
  num_workers: 4
  log_dir: "work/logs_en_de_base"
  ckpt_dir: "work/checkpoints_en_de_base"
  tb_dir: "work/tb_en_de_base"
  save_every: 2000
  eval_every: 5000
  keep_last: 10
  amp: true
  accumulate_steps: 1

decode:
  beam_size: 4
  length_penalty: 0.6
  max_len_offset: 50
  max_len_ratio: 1.0
