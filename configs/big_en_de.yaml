model:
  N: 6
  d_model: 1024
  d_ff: 4096
  num_heads: 16
  dropout: 0.3
  activation: "relu"
  pos_encoding: "sinusoidal"
  label_smoothing: 0.1
  vocab_size: 37000

data:
  dataset: "wmt14"
  lang_pair: "en-de"
  tokenizer_dir: "work/tokenizer_en_de"
  vocab_size: 37000
  max_tokens_per_batch: 45000

optim:
  warmup_steps: 4000
  max_steps: 300000
  lr: 5.0e-4

runtime:
  log_dir: "work/logs_en_de_big"
  ckpt_dir: "work/checkpoints_en_de_big"
  tb_dir: "work/tb_en_de_big"

decode:
  beam_size: 4
  length_penalty: 0.6
